{
 "cells": [
  {
   "cell_type": "markdown",
   "source": [
    "# **Marissa Salas** \n",
    "\n",
    "# Ex 4 The Boys the Amazon Prime series\n",
    "\n",
    "### Investigating reviews of the series and looking for evidence of the mention of the character the Deep\n"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "source": [
    "# Read/open in the text scraped using previous exercise\r\n",
    "f = open('boystxt.txt', 'r')\r\n",
    "text = f.read()\r\n",
    "f.close()\r\n",
    "\r\n",
    "word_bag = text.split()\r\n",
    "print(word_bag[0:100])"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "['\"episodeNumber\":1,\"url\":\"https://www.rottentomatoes.com/tv/the_boys_2019/s01/e01\",\"name\":\"The', 'Name', 'of', 'the', 'Game\",\"description\":\"When', 'a', 'Supe', 'kills', 'the', 'love', 'of', 'his', 'life,', 'A/V', 'salesman', 'Hughie', 'Campbell', 'teams', 'up', 'with', 'Billy', 'Butcher,', 'a', 'vigilante', 'hell-bent', 'on', 'punishing', 'corrupt', 'Supes', '--', 'and', \"Hughie's\", 'life', 'will', 'never', 'be', 'the', 'same', 'again.', '\",\"datePublished\":\"2019-07-25\"},{\"@type\":\"TVEpisode\",\"episodeNumber\":2,\"url\":\"https://www.rottentomatoes.com/tv/the_boys_2019/s01/e02\",\"name\":\"Cherry\",\"description\":\"The', 'Boys', 'get', 'themselves', 'a', 'Superhero,', 'Starlight', 'gets', 'payback,', 'Homelander', 'gets', 'naughty,', 'and', 'a', 'Senator', 'gets', 'naughtier.\",\"datePublished\":\"2019-07-25\"},{\"@type\":\"TVEpisode\",\"episodeNumber\":3,\"url\":\"https://www.rottentomatoes.com/tv/the_boys_2019/s01/e03\",\"name\":\"Get', 'Some\",\"description\":\"It\\'s', 'the', 'race', 'of', 'the', 'century.', 'A-Train', 'versus', 'Shockwave,', 'vying', 'for', 'the', 'title', 'of', \"World's\", 'Fastest', 'Man.', 'Meanwhile,', 'the', 'Boys', 'are', 'reunited', 'and', 'it', 'feels', 'so', 'good.', '\",\"datePublished\":\"2019-07-25\"},{\"@type\":\"TVEpisode\",\"episodeNumber\":4,\"url\":\"https://www.rottentomatoes.com/tv/the_boys_2019/s01/e04\",\"name\":\"The', 'Female', 'of', 'the', 'Species\",\"description\":\"On', 'a', 'very', 'special', 'episode', 'of', 'The', 'Boys...', 'an', 'hour', 'of', 'guts,', 'gutterballs,']\n"
     ]
    }
   ],
   "metadata": {
    "scrolled": true
   }
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "source": [
    "# Create all lower case and split into separate strings\r\n",
    "text = text.lower()\r\n",
    "word_bag = text.split()\r\n",
    "print(word_bag[0:100])"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "['\"episodenumber\":1,\"url\":\"https://www.rottentomatoes.com/tv/the_boys_2019/s01/e01\",\"name\":\"the', 'name', 'of', 'the', 'game\",\"description\":\"when', 'a', 'supe', 'kills', 'the', 'love', 'of', 'his', 'life,', 'a/v', 'salesman', 'hughie', 'campbell', 'teams', 'up', 'with', 'billy', 'butcher,', 'a', 'vigilante', 'hell-bent', 'on', 'punishing', 'corrupt', 'supes', '--', 'and', \"hughie's\", 'life', 'will', 'never', 'be', 'the', 'same', 'again.', '\",\"datepublished\":\"2019-07-25\"},{\"@type\":\"tvepisode\",\"episodenumber\":2,\"url\":\"https://www.rottentomatoes.com/tv/the_boys_2019/s01/e02\",\"name\":\"cherry\",\"description\":\"the', 'boys', 'get', 'themselves', 'a', 'superhero,', 'starlight', 'gets', 'payback,', 'homelander', 'gets', 'naughty,', 'and', 'a', 'senator', 'gets', 'naughtier.\",\"datepublished\":\"2019-07-25\"},{\"@type\":\"tvepisode\",\"episodenumber\":3,\"url\":\"https://www.rottentomatoes.com/tv/the_boys_2019/s01/e03\",\"name\":\"get', 'some\",\"description\":\"it\\'s', 'the', 'race', 'of', 'the', 'century.', 'a-train', 'versus', 'shockwave,', 'vying', 'for', 'the', 'title', 'of', \"world's\", 'fastest', 'man.', 'meanwhile,', 'the', 'boys', 'are', 'reunited', 'and', 'it', 'feels', 'so', 'good.', '\",\"datepublished\":\"2019-07-25\"},{\"@type\":\"tvepisode\",\"episodenumber\":4,\"url\":\"https://www.rottentomatoes.com/tv/the_boys_2019/s01/e04\",\"name\":\"the', 'female', 'of', 'the', 'species\",\"description\":\"on', 'a', 'very', 'special', 'episode', 'of', 'the', 'boys...', 'an', 'hour', 'of', 'guts,', 'gutterballs,']\n"
     ]
    }
   ],
   "metadata": {
    "scrolled": true
   }
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "source": [
    "# Importing re, removing unicode, and cleaning.\r\n",
    "# Processing the text by importing the re library which is regular expression operations. \r\n",
    "# This allows the removal of regular python expressions.\r\n",
    "\r\n",
    "f = open('boystxt.txt', 'r')\r\n",
    "text = f.read()\r\n",
    "f.close()\r\n",
    "\r\n",
    "text = text.lower()\r\n",
    "import re\r\n",
    "word_bag = re.compile(r'\\W+', re.UNICODE).split(text)\r\n",
    "print(word_bag[0:100])"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "['', 'episodenumber', '1', 'url', 'https', 'www', 'rottentomatoes', 'com', 'tv', 'the_boys_2019', 's01', 'e01', 'name', 'the', 'name', 'of', 'the', 'game', 'description', 'when', 'a', 'supe', 'kills', 'the', 'love', 'of', 'his', 'life', 'a', 'v', 'salesman', 'hughie', 'campbell', 'teams', 'up', 'with', 'billy', 'butcher', 'a', 'vigilante', 'hell', 'bent', 'on', 'punishing', 'corrupt', 'supes', 'and', 'hughie', 's', 'life', 'will', 'never', 'be', 'the', 'same', 'again', 'datepublished', '2019', '07', '25', 'type', 'tvepisode', 'episodenumber', '2', 'url', 'https', 'www', 'rottentomatoes', 'com', 'tv', 'the_boys_2019', 's01', 'e02', 'name', 'cherry', 'description', 'the', 'boys', 'get', 'themselves', 'a', 'superhero', 'starlight', 'gets', 'payback', 'homelander', 'gets', 'naughty', 'and', 'a', 'senator', 'gets', 'naughtier', 'datepublished', '2019', '07', '25', 'type', 'tvepisode', 'episodenumber']\n"
     ]
    }
   ],
   "metadata": {
    "scrolled": true
   }
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "source": [
    "# Using functions to prepreocess the text file\r\n",
    "\r\n",
    "def preprocess_text(filename):\r\n",
    "    f = open(filename, 'r')\r\n",
    "    text = f.read()\r\n",
    "    f.close()\r\n",
    "    text = text.lower()\r\n",
    "   # import re\r\n",
    "    return re.compile(r'\\W+', re.UNICODE).split(text)\r\n",
    "\r\n",
    "word_bag = preprocess_text('boystxt.txt')\r\n",
    "print(word_bag[0:100])"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "['', 'episodenumber', '1', 'url', 'https', 'www', 'rottentomatoes', 'com', 'tv', 'the_boys_2019', 's01', 'e01', 'name', 'the', 'name', 'of', 'the', 'game', 'description', 'when', 'a', 'supe', 'kills', 'the', 'love', 'of', 'his', 'life', 'a', 'v', 'salesman', 'hughie', 'campbell', 'teams', 'up', 'with', 'billy', 'butcher', 'a', 'vigilante', 'hell', 'bent', 'on', 'punishing', 'corrupt', 'supes', 'and', 'hughie', 's', 'life', 'will', 'never', 'be', 'the', 'same', 'again', 'datepublished', '2019', '07', '25', 'type', 'tvepisode', 'episodenumber', '2', 'url', 'https', 'www', 'rottentomatoes', 'com', 'tv', 'the_boys_2019', 's01', 'e02', 'name', 'cherry', 'description', 'the', 'boys', 'get', 'themselves', 'a', 'superhero', 'starlight', 'gets', 'payback', 'homelander', 'gets', 'naughty', 'and', 'a', 'senator', 'gets', 'naughtier', 'datepublished', '2019', '07', '25', 'type', 'tvepisode', 'episodenumber']\n"
     ]
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "source": [
    "# Counting the word frequencies and priintint out the pairs\r\n",
    "\r\n",
    "word_freq = []\r\n",
    "for word in word_bag:\r\n",
    "    word_freq.append(word_bag.count(word))\r\n",
    "\r\n",
    "print(\"Frequencies: \" + str(word_freq[0:100]))\r\n",
    "print(\"Pairs: \" + str(list(zip(word_bag[0:100],word_freq[0:100]))))\r\n",
    "\r\n"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Frequencies: [1, 8, 31, 19, 19, 15, 9, 18, 10, 9, 8, 1, 29, 46, 29, 14, 46, 1, 8, 2, 15, 2, 1, 46, 2, 14, 2, 2, 15, 1, 1, 3, 1, 1, 2, 4, 2, 1, 15, 1, 1, 1, 4, 1, 1, 2, 17, 3, 7, 2, 1, 2, 5, 46, 1, 1, 17, 20, 27, 10, 45, 7, 8, 1, 19, 19, 15, 9, 18, 10, 9, 8, 1, 29, 1, 8, 46, 23, 2, 1, 15, 5, 2, 3, 1, 3, 3, 1, 17, 15, 1, 3, 1, 17, 20, 27, 10, 45, 7, 8]\n",
      "Pairs: [('', 1), ('episodenumber', 8), ('1', 31), ('url', 19), ('https', 19), ('www', 15), ('rottentomatoes', 9), ('com', 18), ('tv', 10), ('the_boys_2019', 9), ('s01', 8), ('e01', 1), ('name', 29), ('the', 46), ('name', 29), ('of', 14), ('the', 46), ('game', 1), ('description', 8), ('when', 2), ('a', 15), ('supe', 2), ('kills', 1), ('the', 46), ('love', 2), ('of', 14), ('his', 2), ('life', 2), ('a', 15), ('v', 1), ('salesman', 1), ('hughie', 3), ('campbell', 1), ('teams', 1), ('up', 2), ('with', 4), ('billy', 2), ('butcher', 1), ('a', 15), ('vigilante', 1), ('hell', 1), ('bent', 1), ('on', 4), ('punishing', 1), ('corrupt', 1), ('supes', 2), ('and', 17), ('hughie', 3), ('s', 7), ('life', 2), ('will', 1), ('never', 2), ('be', 5), ('the', 46), ('same', 1), ('again', 1), ('datepublished', 17), ('2019', 20), ('07', 27), ('25', 10), ('type', 45), ('tvepisode', 7), ('episodenumber', 8), ('2', 1), ('url', 19), ('https', 19), ('www', 15), ('rottentomatoes', 9), ('com', 18), ('tv', 10), ('the_boys_2019', 9), ('s01', 8), ('e02', 1), ('name', 29), ('cherry', 1), ('description', 8), ('the', 46), ('boys', 23), ('get', 2), ('themselves', 1), ('a', 15), ('superhero', 5), ('starlight', 2), ('gets', 3), ('payback', 1), ('homelander', 3), ('gets', 3), ('naughty', 1), ('and', 17), ('a', 15), ('senator', 1), ('gets', 3), ('naughtier', 1), ('datepublished', 17), ('2019', 20), ('07', 27), ('25', 10), ('type', 45), ('tvepisode', 7), ('episodenumber', 8)]\n"
     ]
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "source": [
    "# Putting the words into the dictionary using word_bag both as a global and local variable.\r\n",
    "\r\n",
    "def wordsToDictionary(word_bag):\r\n",
    "    word_freq = [word_bag.count(word) for word in word_bag]\r\n",
    "    return dict(list(zip(word_bag,word_freq)))\r\n",
    "\r\n",
    "#test_words = [\"my\",\"words\",\"my\",\"words\",\"no\",\"word\",\"word\",\"word\"]\r\n",
    "counted_words = wordsToDictionary(word_bag)\r\n",
    "print(counted_words)"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "{'': 1, 'episodenumber': 8, '1': 31, 'url': 19, 'https': 19, 'www': 15, 'rottentomatoes': 9, 'com': 18, 'tv': 10, 'the_boys_2019': 9, 's01': 8, 'e01': 1, 'name': 29, 'the': 46, 'of': 14, 'game': 1, 'description': 8, 'when': 2, 'a': 15, 'supe': 2, 'kills': 1, 'love': 2, 'his': 2, 'life': 2, 'v': 1, 'salesman': 1, 'hughie': 3, 'campbell': 1, 'teams': 1, 'up': 2, 'with': 4, 'billy': 2, 'butcher': 1, 'vigilante': 1, 'hell': 1, 'bent': 1, 'on': 4, 'punishing': 1, 'corrupt': 1, 'supes': 2, 'and': 17, 's': 7, 'will': 1, 'never': 2, 'be': 5, 'same': 1, 'again': 1, 'datepublished': 17, '2019': 20, '07': 27, '25': 10, 'type': 45, 'tvepisode': 7, '2': 1, 'e02': 1, 'cherry': 1, 'boys': 23, 'get': 2, 'themselves': 1, 'superhero': 5, 'starlight': 2, 'gets': 3, 'payback': 1, 'homelander': 3, 'naughty': 1, 'senator': 1, 'naughtier': 1, '3': 1, 'e03': 1, 'some': 1, 'it': 7, 'race': 1, 'century': 1, 'train': 2, 'versus': 1, 'shockwave': 1, 'vying': 1, 'for': 4, 'title': 1, 'world': 1, 'fastest': 1, 'man': 1, 'meanwhile': 2, 'are': 2, 'reunited': 1, 'feels': 2, 'so': 2, 'good': 2, '4': 1, 'e04': 1, 'female': 2, 'species': 1, 'very': 4, 'special': 1, 'episode': 1, 'an': 3, 'hour': 1, 'guts': 1, 'gutterballs': 1, 'airplane': 1, 'hijackings': 1, 'madness': 1, 'ghosts': 1, 'one': 2, 'intriguing': 1, 'oh': 1, 'lots': 1, 'heart': 1, 'both': 1, 'in': 9, 'sentimental': 1, 'sense': 2, 'gory': 1, 'literal': 1, '5': 1, 'e05': 1, 'soul': 1, 'head': 1, 'to': 9, 'believe': 1, 'expo': 1, 'follow': 1, 'promising': 1, 'lead': 1, 'their': 2, 'ongoing': 1, 'war': 1, 'against': 1, 'there': 2, 'might': 2, 'homicidal': 1, 'infant': 1, 'but': 4, 'you': 4, 'll': 1, 'have': 2, 'see': 1, 'yourself': 1, '6': 1, 'e06': 1, 'innocents': 1, 'super': 1, 'america': 1, 'features': 1, 'queen': 1, 'maeve': 1, 'black': 1, 'noir': 1, 'deep': 1, 'tara': 1, 'reid': 1, 'zane': 1, '7': 1, 'e07': 1, 'self': 1, 'preservation': 1, 'society': 1, 'trust': 1, 'washed': 1, 'learn': 1, 'this': 2, 'lesson': 1, 'hard': 1, 'way': 1, 'digs': 1, 'into': 1, 'past': 1, 'discovers': 1, 'that': 3, 'hurts': 1, 'if': 2, 're': 1, 'ever': 2, 'sandusky': 1, 'ohio': 1, 'girl': 1, 'asks': 1, 'she': 1, 'can': 1, 'touch': 1, 'your': 2, 'gills': 1, 'say': 2, 'no': 1, '8': 1, 'e08': 1, 'found': 1, 'me': 1, 'season': 3, 'finale': 1, 'time': 1, 'questions': 1, 'answered': 1, 'secrets': 1, 'revealed': 1, 'conflicts': 1, 'conflicted': 1, 'characters': 3, 'exploded': 1, 'much': 3, 'more': 3, 'watch': 1, 'prime': 2, 'genre': 1, 'action': 1, 'adventure': 1, 'image': 1, 'null': 1, 'seasonnumber': 1, 'startdate': 2, 'partofseries': 1, 'tvseries': 1, 'review': 14, 'reviewbody': 10, 'is': 7, 'expert': 1, 'deconstruction': 2, 'stories': 1, 'appropriately': 1, 'wintery': 1, 'view': 1, 'institutional': 1, 'power': 2, 'corporate': 1, 'governmental': 1, 'religious': 1, 'or': 1, 'caped': 1, 'slate': 2, 'culture': 1, '08': 3, 'amazon': 3, 'series': 2, 'comic': 1, 'book': 1, 'adaptation': 1, 'trump': 1, 'marvel': 2, 'html': 2, '18t17': 1, '00': 27, 'reviewrating': 9, 'rating': 9, 'bestrating': 9, 'worstrating': 9, 'ratingvalue': 9, 'author': 9, 'person': 9, 'matthew': 2, 'dessem': 1, 'sourceorganization': 9, 'organization': 9, 'starr': 1, 'moriarty': 1, 'shue': 2, 'bring': 1, 'extra': 1, 'dimensions': 1, 'too': 1, 'making': 1, 'all': 1, 'fun': 1, 'know': 1, 'not': 1, 'dark': 1, 'indiewire': 2, 'spoilers': 1, 'ending': 1, '1202161314': 1, '28t17': 1, 'ben': 1, 'travers': 1, 'isn': 1, 't': 2, 'bold': 1, 'tropes': 1, 'its': 3, 'creators': 1, 'seem': 1, 'think': 1, 'npr': 2, 'org': 2, '26': 1, '743532582': 1, 'satire': 1, 'doesn': 1, 'new': 1, 'says': 1, 'loudly': 1, '25t17': 2, 'glen': 1, 'weldon': 1, 'cast': 1, 'fine': 1, 'particularly': 1, 'who': 2, 'icily': 1, 'effective': 1, 'quaid': 1, 'whose': 1, 'neurotic': 1, 'brave': 1, 'fumblings': 1, 'endearing': 1, 'urban': 1, 'gonzo': 1, 'guide': 1, 'bostonglobe': 1, 'arts': 1, 'television': 1, '24': 1, 'saving': 1, 'these': 1, 'narcissistic': 1, 'superheroes': 2, 'sfpvev6erhppp91zqmkkrl': 1, 'story': 1, '24t17': 2, 'gilbert': 1, 'boston': 1, 'globe': 1, 'fails': 2, 'truly': 2, 'subversive': 2, 'ways': 1, 'count': 1, 'than': 1, 'just': 1, 'wagging': 1, 'middle': 1, 'finger': 1, 'at': 1, 'ceo': 1, 'kevin': 1, 'feige': 1, 'rogerebert': 2, 'demanders': 1, 'amazons': 1, 'anti': 1, 'nick': 1, 'allen': 1, 'damming': 1, 'indictment': 1, 'how': 1, 'corrupts': 1, 'nme': 2, 'reviews': 1, '2535252': 2, '2021': 2, '12t17': 1, 'james': 1, 'mcmahon': 1, 'raw': 1, 'intelligent': 1, 'drama': 1, 'full': 2, 'spanish': 2, 'altafidelidadmagazine': 1, 'mx': 1, 'edicion': 1, 'digital': 1, 'rockstars': 1, 'y': 1, 'dioses': 1, 'caprichosos': 1, '04': 1, 'fausto': 1, 'ponce': 1, 'alta': 1, 'fidelidad': 1, 'magazine': 1, 'spite': 1, 'being': 1, 'best': 1, 'shows': 1, 'about': 1, 'made': 1, 'somewhat': 1, 'safe': 1, 'dull': 1, 'compared': 1, 'twisted': 1, 'work': 1, 'garth': 1, 'ennis': 1, 'codigoespagueti': 1, 'resenas': 1, 'serie': 1, 'critica': 1, '13t17': 1, 'nicolã': 1, 'ruiz': 1, 'cã³digo': 1, 'espagueti': 1, 'yes': 1, 'cynical': 1, 'ultra': 1, 'violent': 1, 'what': 1, 'distinguishes': 1, 'sincere': 1, 'fascination': 1, 'anxieties': 1, 'compulsions': 1, 'human': 1, 'failings': 1, 'cinemastlouis': 1, 'lens': 2, '2020': 1, '09': 1, '08t17': 1, 'andrew': 1, 'wyatt': 1, 'opts': 1, 'social': 1, 'commentary': 1, 'violence': 1, 'depending': 1, 'personal': 1, 'taste': 1, 'may': 1, 'pay': 1, 'dividends': 1, 'weliveentertainment': 1}\n"
     ]
    }
   ],
   "metadata": {
    "scrolled": true
   }
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "source": [
    "# A. Sorting dictionary using our prebuilt method\r\n",
    "\r\n",
    "def sortDictionary(counted_words):\r\n",
    "    aux = [(counted_words[key], key) for key in counted_words]\r\n",
    "    aux.sort()\r\n",
    "    aux.reverse()\r\n",
    "    return aux\r\n",
    "\r\n",
    "counted_words = sortDictionary(counted_words)\r\n",
    "print(counted_words)"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "[(46, 'the'), (45, 'type'), (31, '1'), (29, 'name'), (27, '07'), (27, '00'), (23, 'boys'), (20, '2019'), (19, 'url'), (19, 'https'), (18, 'com'), (17, 'datepublished'), (17, 'and'), (15, 'www'), (15, 'a'), (14, 'review'), (14, 'of'), (10, 'tv'), (10, 'reviewbody'), (10, '25'), (9, 'worstrating'), (9, 'to'), (9, 'the_boys_2019'), (9, 'sourceorganization'), (9, 'rottentomatoes'), (9, 'reviewrating'), (9, 'ratingvalue'), (9, 'rating'), (9, 'person'), (9, 'organization'), (9, 'in'), (9, 'bestrating'), (9, 'author'), (8, 's01'), (8, 'episodenumber'), (8, 'description'), (7, 'tvepisode'), (7, 's'), (7, 'it'), (7, 'is'), (5, 'superhero'), (5, 'be'), (4, 'you'), (4, 'with'), (4, 'very'), (4, 'on'), (4, 'for'), (4, 'but'), (3, 'that'), (3, 'season'), (3, 'much'), (3, 'more'), (3, 'its'), (3, 'hughie'), (3, 'homelander'), (3, 'gets'), (3, 'characters'), (3, 'an'), (3, 'amazon'), (3, '08'), (2, 'your'), (2, 'who'), (2, 'when'), (2, 'up'), (2, 'truly'), (2, 'train'), (2, 'this'), (2, 'there'), (2, 'their'), (2, 't'), (2, 'supes'), (2, 'superheroes'), (2, 'supe'), (2, 'subversive'), (2, 'startdate'), (2, 'starlight'), (2, 'spanish'), (2, 'so'), (2, 'slate'), (2, 'shue'), (2, 'series'), (2, 'sense'), (2, 'say'), (2, 'rogerebert'), (2, 'prime'), (2, 'power'), (2, 'org'), (2, 'one'), (2, 'npr'), (2, 'nme'), (2, 'never'), (2, 'might'), (2, 'meanwhile'), (2, 'matthew'), (2, 'marvel'), (2, 'love'), (2, 'life'), (2, 'lens'), (2, 'indiewire'), (2, 'if'), (2, 'html'), (2, 'his'), (2, 'have'), (2, 'good'), (2, 'get'), (2, 'full'), (2, 'female'), (2, 'feels'), (2, 'fails'), (2, 'ever'), (2, 'deconstruction'), (2, 'billy'), (2, 'are'), (2, '25t17'), (2, '2535252'), (2, '24t17'), (2, '2021'), (1, 'zane'), (1, 'yourself'), (1, 'yes'), (1, 'y'), (1, 'wyatt'), (1, 'world'), (1, 'work'), (1, 'wintery'), (1, 'will'), (1, 'whose'), (1, 'what'), (1, 'weliveentertainment'), (1, 'weldon'), (1, 'ways'), (1, 'way'), (1, 'watch'), (1, 'washed'), (1, 'war'), (1, 'wagging'), (1, 'vying'), (1, 'violent'), (1, 'violence'), (1, 'vigilante'), (1, 'view'), (1, 'versus'), (1, 'v'), (1, 'urban'), (1, 'ultra'), (1, 'twisted'), (1, 'tvseries'), (1, 'trust'), (1, 'trump'), (1, 'tropes'), (1, 'travers'), (1, 'touch'), (1, 'too'), (1, 'title'), (1, 'time'), (1, 'think'), (1, 'these'), (1, 'themselves'), (1, 'than'), (1, 'television'), (1, 'teams'), (1, 'taste'), (1, 'tara'), (1, 'super'), (1, 'story'), (1, 'stories'), (1, 'starr'), (1, 'spoilers'), (1, 'spite'), (1, 'species'), (1, 'special'), (1, 'soul'), (1, 'somewhat'), (1, 'some'), (1, 'society'), (1, 'social'), (1, 'sincere'), (1, 'shows'), (1, 'shockwave'), (1, 'she'), (1, 'sfpvev6erhppp91zqmkkrl'), (1, 'serie'), (1, 'sentimental'), (1, 'senator'), (1, 'self'), (1, 'seem'), (1, 'see'), (1, 'secrets'), (1, 'seasonnumber'), (1, 'says'), (1, 'saving'), (1, 'satire'), (1, 'sandusky'), (1, 'same'), (1, 'salesman'), (1, 'safe'), (1, 'ruiz'), (1, 'rockstars'), (1, 'reviews'), (1, 'revealed'), (1, 'reunited'), (1, 'resenas'), (1, 'religious'), (1, 'reid'), (1, 're'), (1, 'raw'), (1, 'race'), (1, 'questions'), (1, 'queen'), (1, 'quaid'), (1, 'punishing'), (1, 'promising'), (1, 'preservation'), (1, 'ponce'), (1, 'personal'), (1, 'payback'), (1, 'pay'), (1, 'past'), (1, 'partofseries'), (1, 'particularly'), (1, 'or'), (1, 'opts'), (1, 'ongoing'), (1, 'ohio'), (1, 'oh'), (1, 'null'), (1, 'not'), (1, 'noir'), (1, 'no'), (1, 'nicolã'), (1, 'nick'), (1, 'new'), (1, 'neurotic'), (1, 'naughty'), (1, 'naughtier'), (1, 'narcissistic'), (1, 'mx'), (1, 'moriarty'), (1, 'middle'), (1, 'me'), (1, 'mcmahon'), (1, 'may'), (1, 'man'), (1, 'making'), (1, 'magazine'), (1, 'maeve'), (1, 'madness'), (1, 'made'), (1, 'loudly'), (1, 'lots'), (1, 'll'), (1, 'literal'), (1, 'lesson'), (1, 'learn'), (1, 'lead'), (1, 'know'), (1, 'kills'), (1, 'kevin'), (1, 'just'), (1, 'james'), (1, 'isn'), (1, 'intriguing'), (1, 'into'), (1, 'intelligent'), (1, 'institutional'), (1, 'innocents'), (1, 'infant'), (1, 'indictment'), (1, 'image'), (1, 'icily'), (1, 'hurts'), (1, 'human'), (1, 'how'), (1, 'hour'), (1, 'homicidal'), (1, 'hijackings'), (1, 'hell'), (1, 'heart'), (1, 'head'), (1, 'hard'), (1, 'gutterballs'), (1, 'guts'), (1, 'guide'), (1, 'governmental'), (1, 'gory'), (1, 'gonzo'), (1, 'globe'), (1, 'glen'), (1, 'girl'), (1, 'gills'), (1, 'gilbert'), (1, 'ghosts'), (1, 'genre'), (1, 'garth'), (1, 'game'), (1, 'fun'), (1, 'fumblings'), (1, 'found'), (1, 'follow'), (1, 'finger'), (1, 'fine'), (1, 'finale'), (1, 'fidelidad'), (1, 'feige'), (1, 'features'), (1, 'fausto'), (1, 'fastest'), (1, 'fascination'), (1, 'failings'), (1, 'extra'), (1, 'expo'), (1, 'exploded'), (1, 'expert'), (1, 'espagueti'), (1, 'episode'), (1, 'ennis'), (1, 'ending'), (1, 'endearing'), (1, 'effective'), (1, 'edicion'), (1, 'e08'), (1, 'e07'), (1, 'e06'), (1, 'e05'), (1, 'e04'), (1, 'e03'), (1, 'e02'), (1, 'e01'), (1, 'dull'), (1, 'drama'), (1, 'doesn'), (1, 'dividends'), (1, 'distinguishes'), (1, 'discovers'), (1, 'dioses'), (1, 'dimensions'), (1, 'digs'), (1, 'digital'), (1, 'dessem'), (1, 'depending'), (1, 'demanders'), (1, 'deep'), (1, 'dark'), (1, 'damming'), (1, 'cã³digo'), (1, 'cynical'), (1, 'culture'), (1, 'critica'), (1, 'creators'), (1, 'count'), (1, 'corrupts'), (1, 'corrupt'), (1, 'corporate'), (1, 'conflicts'), (1, 'conflicted'), (1, 'compulsions'), (1, 'compared'), (1, 'commentary'), (1, 'comic'), (1, 'codigoespagueti'), (1, 'cinemastlouis'), (1, 'cherry'), (1, 'ceo'), (1, 'century'), (1, 'cast'), (1, 'caprichosos'), (1, 'caped'), (1, 'can'), (1, 'campbell'), (1, 'butcher'), (1, 'bring'), (1, 'brave'), (1, 'both'), (1, 'bostonglobe'), (1, 'boston'), (1, 'book'), (1, 'bold'), (1, 'black'), (1, 'best'), (1, 'bent'), (1, 'ben'), (1, 'believe'), (1, 'being'), (1, 'at'), (1, 'asks'), (1, 'arts'), (1, 'appropriately'), (1, 'anxieties'), (1, 'anti'), (1, 'answered'), (1, 'andrew'), (1, 'america'), (1, 'amazons'), (1, 'altafidelidadmagazine'), (1, 'alta'), (1, 'allen'), (1, 'all'), (1, 'airplane'), (1, 'against'), (1, 'again'), (1, 'adventure'), (1, 'adaptation'), (1, 'action'), (1, 'about'), (1, '8'), (1, '743532582'), (1, '7'), (1, '6'), (1, '5'), (1, '4'), (1, '3'), (1, '28t17'), (1, '26'), (1, '24'), (1, '2020'), (1, '2'), (1, '18t17'), (1, '13t17'), (1, '12t17'), (1, '1202161314'), (1, '09'), (1, '08t17'), (1, '04'), (1, '')]\n"
     ]
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "source": [
    "# Creating and using a stopwords function with an array that can be added to for more removal of words\r\n",
    "stopwords = ['a','n','the','my', 'url', 'https', 'of', 'an', 'org', 'www', 'com', 'and', 'to']\r\n",
    "def removeStopWords(word_bag, stopwords):\r\n",
    "    return [w for w in word_bag if w not in stopwords]\r\n",
    "test_words = removeStopWords(word_bag, stopwords)\r\n",
    "counted_words = wordsToDictionary(test_words)\r\n",
    "counted_words = sortDictionary(counted_words)\r\n",
    "print(counted_words)"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "[(45, 'type'), (31, '1'), (29, 'name'), (27, '07'), (27, '00'), (23, 'boys'), (20, '2019'), (17, 'datepublished'), (14, 'review'), (10, 'tv'), (10, 'reviewbody'), (10, '25'), (9, 'worstrating'), (9, 'the_boys_2019'), (9, 'sourceorganization'), (9, 'rottentomatoes'), (9, 'reviewrating'), (9, 'ratingvalue'), (9, 'rating'), (9, 'person'), (9, 'organization'), (9, 'in'), (9, 'bestrating'), (9, 'author'), (8, 's01'), (8, 'episodenumber'), (8, 'description'), (7, 'tvepisode'), (7, 's'), (7, 'it'), (7, 'is'), (5, 'superhero'), (5, 'be'), (4, 'you'), (4, 'with'), (4, 'very'), (4, 'on'), (4, 'for'), (4, 'but'), (3, 'that'), (3, 'season'), (3, 'much'), (3, 'more'), (3, 'its'), (3, 'hughie'), (3, 'homelander'), (3, 'gets'), (3, 'characters'), (3, 'amazon'), (3, '08'), (2, 'your'), (2, 'who'), (2, 'when'), (2, 'up'), (2, 'truly'), (2, 'train'), (2, 'this'), (2, 'there'), (2, 'their'), (2, 't'), (2, 'supes'), (2, 'superheroes'), (2, 'supe'), (2, 'subversive'), (2, 'startdate'), (2, 'starlight'), (2, 'spanish'), (2, 'so'), (2, 'slate'), (2, 'shue'), (2, 'series'), (2, 'sense'), (2, 'say'), (2, 'rogerebert'), (2, 'prime'), (2, 'power'), (2, 'one'), (2, 'npr'), (2, 'nme'), (2, 'never'), (2, 'might'), (2, 'meanwhile'), (2, 'matthew'), (2, 'marvel'), (2, 'love'), (2, 'life'), (2, 'lens'), (2, 'indiewire'), (2, 'if'), (2, 'html'), (2, 'his'), (2, 'have'), (2, 'good'), (2, 'get'), (2, 'full'), (2, 'female'), (2, 'feels'), (2, 'fails'), (2, 'ever'), (2, 'deconstruction'), (2, 'billy'), (2, 'are'), (2, '25t17'), (2, '2535252'), (2, '24t17'), (2, '2021'), (1, 'zane'), (1, 'yourself'), (1, 'yes'), (1, 'y'), (1, 'wyatt'), (1, 'world'), (1, 'work'), (1, 'wintery'), (1, 'will'), (1, 'whose'), (1, 'what'), (1, 'weliveentertainment'), (1, 'weldon'), (1, 'ways'), (1, 'way'), (1, 'watch'), (1, 'washed'), (1, 'war'), (1, 'wagging'), (1, 'vying'), (1, 'violent'), (1, 'violence'), (1, 'vigilante'), (1, 'view'), (1, 'versus'), (1, 'v'), (1, 'urban'), (1, 'ultra'), (1, 'twisted'), (1, 'tvseries'), (1, 'trust'), (1, 'trump'), (1, 'tropes'), (1, 'travers'), (1, 'touch'), (1, 'too'), (1, 'title'), (1, 'time'), (1, 'think'), (1, 'these'), (1, 'themselves'), (1, 'than'), (1, 'television'), (1, 'teams'), (1, 'taste'), (1, 'tara'), (1, 'super'), (1, 'story'), (1, 'stories'), (1, 'starr'), (1, 'spoilers'), (1, 'spite'), (1, 'species'), (1, 'special'), (1, 'soul'), (1, 'somewhat'), (1, 'some'), (1, 'society'), (1, 'social'), (1, 'sincere'), (1, 'shows'), (1, 'shockwave'), (1, 'she'), (1, 'sfpvev6erhppp91zqmkkrl'), (1, 'serie'), (1, 'sentimental'), (1, 'senator'), (1, 'self'), (1, 'seem'), (1, 'see'), (1, 'secrets'), (1, 'seasonnumber'), (1, 'says'), (1, 'saving'), (1, 'satire'), (1, 'sandusky'), (1, 'same'), (1, 'salesman'), (1, 'safe'), (1, 'ruiz'), (1, 'rockstars'), (1, 'reviews'), (1, 'revealed'), (1, 'reunited'), (1, 'resenas'), (1, 'religious'), (1, 'reid'), (1, 're'), (1, 'raw'), (1, 'race'), (1, 'questions'), (1, 'queen'), (1, 'quaid'), (1, 'punishing'), (1, 'promising'), (1, 'preservation'), (1, 'ponce'), (1, 'personal'), (1, 'payback'), (1, 'pay'), (1, 'past'), (1, 'partofseries'), (1, 'particularly'), (1, 'or'), (1, 'opts'), (1, 'ongoing'), (1, 'ohio'), (1, 'oh'), (1, 'null'), (1, 'not'), (1, 'noir'), (1, 'no'), (1, 'nicolã'), (1, 'nick'), (1, 'new'), (1, 'neurotic'), (1, 'naughty'), (1, 'naughtier'), (1, 'narcissistic'), (1, 'mx'), (1, 'moriarty'), (1, 'middle'), (1, 'me'), (1, 'mcmahon'), (1, 'may'), (1, 'man'), (1, 'making'), (1, 'magazine'), (1, 'maeve'), (1, 'madness'), (1, 'made'), (1, 'loudly'), (1, 'lots'), (1, 'll'), (1, 'literal'), (1, 'lesson'), (1, 'learn'), (1, 'lead'), (1, 'know'), (1, 'kills'), (1, 'kevin'), (1, 'just'), (1, 'james'), (1, 'isn'), (1, 'intriguing'), (1, 'into'), (1, 'intelligent'), (1, 'institutional'), (1, 'innocents'), (1, 'infant'), (1, 'indictment'), (1, 'image'), (1, 'icily'), (1, 'hurts'), (1, 'human'), (1, 'how'), (1, 'hour'), (1, 'homicidal'), (1, 'hijackings'), (1, 'hell'), (1, 'heart'), (1, 'head'), (1, 'hard'), (1, 'gutterballs'), (1, 'guts'), (1, 'guide'), (1, 'governmental'), (1, 'gory'), (1, 'gonzo'), (1, 'globe'), (1, 'glen'), (1, 'girl'), (1, 'gills'), (1, 'gilbert'), (1, 'ghosts'), (1, 'genre'), (1, 'garth'), (1, 'game'), (1, 'fun'), (1, 'fumblings'), (1, 'found'), (1, 'follow'), (1, 'finger'), (1, 'fine'), (1, 'finale'), (1, 'fidelidad'), (1, 'feige'), (1, 'features'), (1, 'fausto'), (1, 'fastest'), (1, 'fascination'), (1, 'failings'), (1, 'extra'), (1, 'expo'), (1, 'exploded'), (1, 'expert'), (1, 'espagueti'), (1, 'episode'), (1, 'ennis'), (1, 'ending'), (1, 'endearing'), (1, 'effective'), (1, 'edicion'), (1, 'e08'), (1, 'e07'), (1, 'e06'), (1, 'e05'), (1, 'e04'), (1, 'e03'), (1, 'e02'), (1, 'e01'), (1, 'dull'), (1, 'drama'), (1, 'doesn'), (1, 'dividends'), (1, 'distinguishes'), (1, 'discovers'), (1, 'dioses'), (1, 'dimensions'), (1, 'digs'), (1, 'digital'), (1, 'dessem'), (1, 'depending'), (1, 'demanders'), (1, 'deep'), (1, 'dark'), (1, 'damming'), (1, 'cã³digo'), (1, 'cynical'), (1, 'culture'), (1, 'critica'), (1, 'creators'), (1, 'count'), (1, 'corrupts'), (1, 'corrupt'), (1, 'corporate'), (1, 'conflicts'), (1, 'conflicted'), (1, 'compulsions'), (1, 'compared'), (1, 'commentary'), (1, 'comic'), (1, 'codigoespagueti'), (1, 'cinemastlouis'), (1, 'cherry'), (1, 'ceo'), (1, 'century'), (1, 'cast'), (1, 'caprichosos'), (1, 'caped'), (1, 'can'), (1, 'campbell'), (1, 'butcher'), (1, 'bring'), (1, 'brave'), (1, 'both'), (1, 'bostonglobe'), (1, 'boston'), (1, 'book'), (1, 'bold'), (1, 'black'), (1, 'best'), (1, 'bent'), (1, 'ben'), (1, 'believe'), (1, 'being'), (1, 'at'), (1, 'asks'), (1, 'arts'), (1, 'appropriately'), (1, 'anxieties'), (1, 'anti'), (1, 'answered'), (1, 'andrew'), (1, 'america'), (1, 'amazons'), (1, 'altafidelidadmagazine'), (1, 'alta'), (1, 'allen'), (1, 'all'), (1, 'airplane'), (1, 'against'), (1, 'again'), (1, 'adventure'), (1, 'adaptation'), (1, 'action'), (1, 'about'), (1, '8'), (1, '743532582'), (1, '7'), (1, '6'), (1, '5'), (1, '4'), (1, '3'), (1, '28t17'), (1, '26'), (1, '24'), (1, '2020'), (1, '2'), (1, '18t17'), (1, '13t17'), (1, '12t17'), (1, '1202161314'), (1, '09'), (1, '08t17'), (1, '04'), (1, '')]\n"
     ]
    }
   ],
   "metadata": {
    "scrolled": true
   }
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "source": [
    "#B. Printing the top five most frequent words from your data\r\n",
    "x = 0\r\n",
    "for i in range (5):\r\n",
    "    print(counted_words [x])\r\n",
    "    x = x + 1"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "(45, 'type')\n",
      "(31, '1')\n",
      "(29, 'name')\n",
      "(27, '07')\n",
      "(27, '00')\n"
     ]
    }
   ],
   "metadata": {
    "scrolled": true
   }
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "source": [
    "# C. Querying for certain key words and printing their frequency\r\n",
    "\r\n",
    "def wordsToDictionary(word_bag):\r\n",
    "    word_freq = [word_bag.count(word) for word in word_bag]\r\n",
    "    return dict(list(zip(word_bag,word_freq)))\r\n",
    "\r\n",
    "test_words = [\"gills\",\"rape\",\"misogyny\",\"deep\",\"butcher\",\"starr\"]\r\n",
    "counted_words = wordsToDictionary(test_words)\r\n",
    "print(\"Words of interest:\", counted_words)"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Words of interest: {'gills': 1, 'rape': 1, 'misogyny': 1, 'deep': 1, 'butcher': 1, 'starr': 1}\n"
     ]
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "source": [
    "# D. Comparing the relative frequency of words of interest\r\n",
    "\r\n",
    "lenword = len(counted_words) #total of items in my list which is 6\r\n",
    "#print (lenword)\r\n",
    "\r\n",
    "# Use loops to check each word's frequency against another \r\n",
    "\r\n",
    "for i in range(lenword):\r\n",
    "    for x in range(i+1, lenword):\r\n",
    "        if counted_words.get(test_words[i]) == counted_words.get(test_words[x]):\r\n",
    "            print(test_words[i] + \" occurs the same number of times as \" + test_words[x])\r\n",
    "        elif counted_words.get(test_words[i]) > counted_words.get(test_words[x]):\r\n",
    "            print(test_words[i] + \" occurs more times than \" + test_words[x])\r\n",
    "        elif counted_words.get(test_words[i]) < counted_words.get(test_words[x]):\r\n",
    "            print(test_words[i] + \" occurs less times than \" + test_words[x])\r\n",
    "    \r\n"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "gills occurs the same number of times as rape\n",
      "gills occurs the same number of times as misogyny\n",
      "gills occurs the same number of times as deep\n",
      "gills occurs the same number of times as butcher\n",
      "gills occurs the same number of times as starr\n",
      "rape occurs the same number of times as misogyny\n",
      "rape occurs the same number of times as deep\n",
      "rape occurs the same number of times as butcher\n",
      "rape occurs the same number of times as starr\n",
      "misogyny occurs the same number of times as deep\n",
      "misogyny occurs the same number of times as butcher\n",
      "misogyny occurs the same number of times as starr\n",
      "deep occurs the same number of times as butcher\n",
      "deep occurs the same number of times as starr\n",
      "butcher occurs the same number of times as starr\n"
     ]
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [],
   "outputs": [],
   "metadata": {}
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}